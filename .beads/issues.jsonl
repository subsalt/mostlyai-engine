{"id":"mostlyai-engine-34q","title":"Summarize existing architecture","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T09:55:38.869926996-08:00","updated_at":"2025-12-10T11:36:56.336194368-08:00","closed_at":"2025-12-10T11:36:56.336194368-08:00"}
{"id":"mostlyai-engine-7mn","title":"Slim ARGN - Optimize for Distributed Cluster Environment","description":"Optimize mostlyai-engine for distributed Ray cluster. Goals: (1) Eliminate disk I/O during inference, (2) Reduce model artifact size ~50%, (3) Streamline training without workspace files, (4) Enable Ray Data streaming for large datasets. See history/IMPLEMENTATION_PLAN.md for details.","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-18T13:14:54.740419-08:00","updated_at":"2025-12-18T13:14:54.740419-08:00"}
{"id":"mostlyai-engine-7mn.1","title":"Create ModelArtifact dataclass with serialization","description":"Create mostlyai/engine/_artifact.py with ModelArtifact dataclass. Include: weights (compressed bytes), model architecture params (is_sequential, model_size, cardinalities), stats for encoding/decoding, key columns. Implement to_bytes() and from_bytes() for serialization.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-18T13:15:00.992928-08:00","updated_at":"2025-12-18T16:42:35.961704-08:00","closed_at":"2025-12-18T16:42:35.961704-08:00","dependencies":[{"issue_id":"mostlyai-engine-7mn.1","depends_on_id":"mostlyai-engine-7mn","type":"parent-child","created_at":"2025-12-18T13:15:00.99355-08:00","created_by":"daemon"}]}
{"id":"mostlyai-engine-7mn.10","title":"Implement train_sequential() for longitudinal data","description":"Add train_sequential() to training.py for longitudinal models. Takes tgt_data + ctx_data, handles context encoding, sequential windowing. Returns ModelArtifact with sequential model weights.","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-18T13:15:46.999355-08:00","updated_at":"2025-12-18T13:15:46.999355-08:00","dependencies":[{"issue_id":"mostlyai-engine-7mn.10","depends_on_id":"mostlyai-engine-7mn","type":"parent-child","created_at":"2025-12-18T13:15:46.999954-08:00","created_by":"daemon"},{"issue_id":"mostlyai-engine-7mn.10","depends_on_id":"mostlyai-engine-7mn.9","type":"blocks","created_at":"2025-12-18T13:17:06.730673-08:00","created_by":"daemon"}]}
{"id":"mostlyai-engine-7mn.11","title":"Add Phase 2 tests to slim-argn.py","description":"Add test_phase2_training() to slim-argn.py. Validate train_flat() produces models equivalent to workspace-based training. Compare loss values, generated sample distributions.","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-18T13:15:51.687949-08:00","updated_at":"2025-12-18T13:15:51.687949-08:00","dependencies":[{"issue_id":"mostlyai-engine-7mn.11","depends_on_id":"mostlyai-engine-7mn","type":"parent-child","created_at":"2025-12-18T13:15:51.688796-08:00","created_by":"daemon"},{"issue_id":"mostlyai-engine-7mn.11","depends_on_id":"mostlyai-engine-7mn.10","type":"blocks","created_at":"2025-12-18T13:17:06.967809-08:00","created_by":"daemon"}]}
{"id":"mostlyai-engine-7mn.12","title":"Implement distributed stats computation for Ray Data","description":"Create mostlyai/engine/distributed.py with compute_partial_stats() and combine_partial_stats(). Enable map/reduce pattern for distributed stats computation with Ray Data.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-18T13:15:58.32463-08:00","updated_at":"2025-12-18T13:15:58.32463-08:00","dependencies":[{"issue_id":"mostlyai-engine-7mn.12","depends_on_id":"mostlyai-engine-7mn","type":"parent-child","created_at":"2025-12-18T13:15:58.32527-08:00","created_by":"daemon"},{"issue_id":"mostlyai-engine-7mn.12","depends_on_id":"mostlyai-engine-7mn.11","type":"blocks","created_at":"2025-12-18T13:17:36.189152-08:00","created_by":"daemon"}]}
{"id":"mostlyai-engine-7mn.13","title":"Implement encode_batch_for_ray() streaming encoding","description":"Add encode_batch_for_ray() to distributed.py. Returns dict of numpy arrays for Ray Data compatibility. Enable streaming encoding via map_batches().","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-18T13:16:02.748945-08:00","updated_at":"2025-12-18T13:16:02.748945-08:00","dependencies":[{"issue_id":"mostlyai-engine-7mn.13","depends_on_id":"mostlyai-engine-7mn","type":"parent-child","created_at":"2025-12-18T13:16:02.749639-08:00","created_by":"daemon"},{"issue_id":"mostlyai-engine-7mn.13","depends_on_id":"mostlyai-engine-7mn.12","type":"blocks","created_at":"2025-12-18T13:17:36.425629-08:00","created_by":"daemon"}]}
{"id":"mostlyai-engine-7mn.14","title":"Create Ray Data integration example and tests","description":"Add Phase 3 tests to slim-argn.py demonstrating full Ray Data pipeline: distributed stats, streaming encode, tensor iteration to training. Document integration pattern.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-18T13:16:07.575217-08:00","updated_at":"2025-12-18T13:16:07.575217-08:00","dependencies":[{"issue_id":"mostlyai-engine-7mn.14","depends_on_id":"mostlyai-engine-7mn","type":"parent-child","created_at":"2025-12-18T13:16:07.575823-08:00","created_by":"daemon"},{"issue_id":"mostlyai-engine-7mn.14","depends_on_id":"mostlyai-engine-7mn.13","type":"blocks","created_at":"2025-12-18T13:17:36.662185-08:00","created_by":"daemon"}]}
{"id":"mostlyai-engine-7mn.15","title":"Update subsalt TabularARGNModule for artifact format","description":"Replace generators/tabular_argn/model.py to use artifact format exclusively. Use model_artifact_bytes parameter. sample() uses generate_flat(). Remove tarball support entirely.","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-18T13:16:12.979856-08:00","updated_at":"2025-12-18T13:20:40.238293-08:00","dependencies":[{"issue_id":"mostlyai-engine-7mn.15","depends_on_id":"mostlyai-engine-7mn","type":"parent-child","created_at":"2025-12-18T13:16:12.980407-08:00","created_by":"daemon"},{"issue_id":"mostlyai-engine-7mn.15","depends_on_id":"mostlyai-engine-7mn.7","type":"blocks","created_at":"2025-12-18T13:17:36.896643-08:00","created_by":"daemon"}]}
{"id":"mostlyai-engine-7mn.16","title":"Update subsalt TabularARGNTrainer to use new training API","description":"Replace generators/tabular_argn/trainer.py to use train_flat() exclusively. Remove workspace-based split/analyze/encode/train. Simpler, cleaner implementation.","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-18T13:16:17.61744-08:00","updated_at":"2025-12-18T13:20:40.499688-08:00","dependencies":[{"issue_id":"mostlyai-engine-7mn.16","depends_on_id":"mostlyai-engine-7mn","type":"parent-child","created_at":"2025-12-18T13:16:17.618013-08:00","created_by":"daemon"},{"issue_id":"mostlyai-engine-7mn.16","depends_on_id":"mostlyai-engine-7mn.11","type":"blocks","created_at":"2025-12-18T13:17:37.129433-08:00","created_by":"daemon"}]}
{"id":"mostlyai-engine-7mn.2","title":"Implement stats minimization functions","description":"Add minimize_column_stats() and minimize_stats() to _artifact.py. Strip value protection metadata (cnt_values, no_of_rare_categories, value_protection flags). Keep only essential fields for encoding/decoding: codes, cardinalities, bins, encoding_type, argn identifiers.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-18T13:15:06.385849-08:00","updated_at":"2025-12-18T16:50:39.029629-08:00","closed_at":"2025-12-18T16:50:39.029629-08:00","dependencies":[{"issue_id":"mostlyai-engine-7mn.2","depends_on_id":"mostlyai-engine-7mn","type":"parent-child","created_at":"2025-12-18T13:15:06.386451-08:00","created_by":"daemon"},{"issue_id":"mostlyai-engine-7mn.2","depends_on_id":"mostlyai-engine-7mn.1","type":"blocks","created_at":"2025-12-18T13:16:42.932804-08:00","created_by":"daemon"}]}
{"id":"mostlyai-engine-7mn.3","title":"Implement ModelArtifact.from_workspace() migration","description":"Add from_workspace() classmethod to ModelArtifact. Load stats JSON, model weights, and model configs from existing workspace directory. Compress weights with zlib. This enables migration from tarball format to artifact format.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-18T13:15:11.70356-08:00","updated_at":"2025-12-18T13:20:20.385497-08:00","closed_at":"2025-12-18T13:20:20.385497-08:00","dependencies":[{"issue_id":"mostlyai-engine-7mn.3","depends_on_id":"mostlyai-engine-7mn","type":"parent-child","created_at":"2025-12-18T13:15:11.705398-08:00","created_by":"daemon"},{"issue_id":"mostlyai-engine-7mn.3","depends_on_id":"mostlyai-engine-7mn.1","type":"blocks","created_at":"2025-12-18T13:16:43.162295-08:00","created_by":"daemon"},{"issue_id":"mostlyai-engine-7mn.3","depends_on_id":"mostlyai-engine-7mn.2","type":"blocks","created_at":"2025-12-18T13:16:43.396928-08:00","created_by":"daemon"}]}
{"id":"mostlyai-engine-7mn.4","title":"Implement generate_flat() in-memory generation","description":"Create generation_core.py with generate_flat_core(). Reconstruct model from artifact weights, encode context in memory, run generation loop, decode results. No disk I/O. Add generate_flat() wrapper in generation.py. Test with freshly trained models.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-18T13:15:16.762938-08:00","updated_at":"2025-12-18T17:37:15.694515-08:00","closed_at":"2025-12-18T17:37:15.694515-08:00","dependencies":[{"issue_id":"mostlyai-engine-7mn.4","depends_on_id":"mostlyai-engine-7mn","type":"parent-child","created_at":"2025-12-18T13:15:16.763591-08:00","created_by":"daemon"},{"issue_id":"mostlyai-engine-7mn.4","depends_on_id":"mostlyai-engine-7mn.3","type":"blocks","created_at":"2025-12-18T13:16:43.6334-08:00","created_by":"daemon"},{"issue_id":"mostlyai-engine-7mn.4","depends_on_id":"mostlyai-engine-7mn.2","type":"blocks","created_at":"2025-12-18T13:20:29.176792-08:00","created_by":"daemon"}]}
{"id":"mostlyai-engine-7mn.5","title":"Implement generate_sequential() in-memory generation","description":"Add generate_sequential_core() to generation_core.py for longitudinal/sequential data. Handle sequence generation loop, context encoding, history compression. Add generate_sequential() wrapper in generation.py.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-18T13:15:21.463349-08:00","updated_at":"2025-12-19T15:25:44.421778-08:00","closed_at":"2025-12-19T15:25:44.421778-08:00","close_reason":"Implemented generate_sequential_core with helper functions for positional columns, sequence continuation, and ITT decoding","dependencies":[{"issue_id":"mostlyai-engine-7mn.5","depends_on_id":"mostlyai-engine-7mn","type":"parent-child","created_at":"2025-12-18T13:15:21.463952-08:00","created_by":"daemon"},{"issue_id":"mostlyai-engine-7mn.5","depends_on_id":"mostlyai-engine-7mn.4","type":"blocks","created_at":"2025-12-18T13:16:43.863264-08:00","created_by":"daemon"}]}
{"id":"mostlyai-engine-7mn.6","title":"Update __init__.py exports for new API","description":"Export ModelArtifact, generate_flat, generate_sequential from mostlyai/engine/__init__.py. Keep backward compatibility with existing exports.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-18T13:15:25.583288-08:00","updated_at":"2025-12-19T15:29:25.642944-08:00","closed_at":"2025-12-19T15:29:25.642944-08:00","close_reason":"Added ModelArtifact, minimize_stats, generate_flat, generate_sequential to __init__.py exports","dependencies":[{"issue_id":"mostlyai-engine-7mn.6","depends_on_id":"mostlyai-engine-7mn","type":"parent-child","created_at":"2025-12-18T13:15:25.583895-08:00","created_by":"daemon"},{"issue_id":"mostlyai-engine-7mn.6","depends_on_id":"mostlyai-engine-7mn.4","type":"blocks","created_at":"2025-12-18T13:16:44.096178-08:00","created_by":"daemon"},{"issue_id":"mostlyai-engine-7mn.6","depends_on_id":"mostlyai-engine-7mn.5","type":"blocks","created_at":"2025-12-18T13:16:44.326359-08:00","created_by":"daemon"}]}
{"id":"mostlyai-engine-7mn.7","title":"Create slim-argn.py test script for Phase 1 validation","description":"Create slim-argn.py test script runnable via cluster-run.sh. Test: (1) Artifact roundtrip serialization, (2) generate_flat matches workspace-based generate, (3) Artifact size vs tarball size comparison. Validates Phase 1 implementation.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-18T13:15:32.255396-08:00","updated_at":"2025-12-19T15:29:34.168897-08:00","closed_at":"2025-12-19T15:29:34.168897-08:00","close_reason":"Updated slim-argn.py with test_sequential_artifact_generation() for context+target table testing","dependencies":[{"issue_id":"mostlyai-engine-7mn.7","depends_on_id":"mostlyai-engine-7mn","type":"parent-child","created_at":"2025-12-18T13:15:32.256156-08:00","created_by":"daemon"},{"issue_id":"mostlyai-engine-7mn.7","depends_on_id":"mostlyai-engine-7mn.6","type":"blocks","created_at":"2025-12-18T13:16:44.563623-08:00","created_by":"daemon"}]}
{"id":"mostlyai-engine-7mn.8","title":"Implement compute_stats() in-memory stats computation","description":"Create mostlyai/engine/stats.py with compute_stats(df, encoding_types). Replace analyze() file-based workflow with direct in-memory computation. Skip value protection. Return stats dict directly.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-18T13:15:37.530939-08:00","updated_at":"2025-12-19T15:37:42.185159-08:00","closed_at":"2025-12-19T15:37:42.185159-08:00","close_reason":"Implemented compute_stats() using existing analyze functions, skipping value protection","dependencies":[{"issue_id":"mostlyai-engine-7mn.8","depends_on_id":"mostlyai-engine-7mn","type":"parent-child","created_at":"2025-12-18T13:15:37.531642-08:00","created_by":"daemon"},{"issue_id":"mostlyai-engine-7mn.8","depends_on_id":"mostlyai-engine-7mn.7","type":"blocks","created_at":"2025-12-18T13:17:06.260737-08:00","created_by":"daemon"}]}
{"id":"mostlyai-engine-7mn.9","title":"Implement train_flat() end-to-end training","description":"Add train_flat() to training.py. Takes DataFrame + encoding_types, computes stats, encodes data, trains model, returns ModelArtifact. No workspace files. Uses existing tensor interface internally.","status":"in_progress","priority":1,"issue_type":"task","created_at":"2025-12-18T13:15:42.609402-08:00","updated_at":"2025-12-19T15:39:20.607762-08:00","dependencies":[{"issue_id":"mostlyai-engine-7mn.9","depends_on_id":"mostlyai-engine-7mn","type":"parent-child","created_at":"2025-12-18T13:15:42.609975-08:00","created_by":"daemon"},{"issue_id":"mostlyai-engine-7mn.9","depends_on_id":"mostlyai-engine-7mn.8","type":"blocks","created_at":"2025-12-18T13:17:06.496226-08:00","created_by":"daemon"}]}
{"id":"mostlyai-engine-g4m","title":"Training Pipeline Optimization - Eliminate CPU Bottlenecks","description":"Optimize TabularARGN training to eliminate CPU bottlenecks causing 1-25% GPU utilization. Goal: achieve 70-90%+ GPU utilization by moving data transformations out of the training loop and enabling direct tensor input from Ray Data pipelines. See docs/TRAINING_TENSOR_INTERFACE_DESIGN.md for full design.","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-10T11:37:05.442668066-08:00","updated_at":"2025-12-10T11:38:41.346974772-08:00"}
{"id":"mostlyai-engine-g4m.1","title":"Run baseline benchmarks (1M rows longitudinal)","description":"Run training_benchmark.py with 1M row longitudinal dataset to establish baseline timing metrics before optimization. Record: total time, train time per epoch, GPU utilization, loss trajectory.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T11:39:03.00401884-08:00","updated_at":"2025-12-10T11:53:35.937427701-08:00","closed_at":"2025-12-10T11:53:35.937427701-08:00","dependencies":[{"issue_id":"mostlyai-engine-g4m.1","depends_on_id":"mostlyai-engine-g4m","type":"parent-child","created_at":"2025-12-10T11:39:03.005850206-08:00","created_by":"daemon"}]}
{"id":"mostlyai-engine-g4m.10","title":"Document Ray Data integration pattern for subsalt trainers","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T12:03:21.632315431-08:00","updated_at":"2025-12-10T16:17:53.169571445-08:00","closed_at":"2025-12-10T16:17:53.169571445-08:00","dependencies":[{"issue_id":"mostlyai-engine-g4m.10","depends_on_id":"mostlyai-engine-g4m","type":"parent-child","created_at":"2025-12-10T12:03:21.633285926-08:00","created_by":"daemon"}]}
{"id":"mostlyai-engine-g4m.11","title":"Integrate tensor interface into subsalt TabularARGN trainers","description":"Update TabularARGNTrainer and TabularARGNLongitudinalTrainer in subsalt to use the new tensor interface. Key considerations: (1) Run tensor conversion on CPU to avoid GPU contention (25-50x more CPUs than GPUs available), (2) Stream tensors via Ray Data iter_batches(), (3) Build model_config from analyze() results. Depends on tasks .5, .6, .8, .9 being complete.","status":"in_progress","priority":1,"issue_type":"task","created_at":"2025-12-10T12:13:22.959952899-08:00","updated_at":"2025-12-10T16:18:22.014639654-08:00","dependencies":[{"issue_id":"mostlyai-engine-g4m.11","depends_on_id":"mostlyai-engine-g4m","type":"parent-child","created_at":"2025-12-10T12:13:22.960986696-08:00","created_by":"daemon"}]}
{"id":"mostlyai-engine-g4m.2","title":"Create tensor_utils.py with prepare_flat_batch and prepare_sequential_batch","description":"Implement mostlyai/engine/_tabular/tensor_utils.py with functions to convert encoded data directly to GPU tensors. Include: prepare_flat_batch(), prepare_sequential_batch(), create_sequence_windows(). These replace BatchCollator's per-batch transformations.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T11:39:09.639394961-08:00","updated_at":"2025-12-10T11:52:45.816254555-08:00","closed_at":"2025-12-10T11:52:45.816254555-08:00","dependencies":[{"issue_id":"mostlyai-engine-g4m.2","depends_on_id":"mostlyai-engine-g4m","type":"parent-child","created_at":"2025-12-10T11:39:09.643572132-08:00","created_by":"daemon"}]}
{"id":"mostlyai-engine-g4m.3","title":"Add train_tensors parameter to train() function","description":"Modify mostlyai/engine/_tabular/training.py train() function to accept optional train_tensors and val_tensors Iterator[dict[str, torch.Tensor]] parameters. When provided, bypass DataLoader/BatchCollator creation and use tensors directly. Requires model_config dict for cardinalities.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T11:39:15.836180063-08:00","updated_at":"2025-12-10T12:09:50.632662108-08:00","closed_at":"2025-12-10T12:09:50.632662108-08:00","dependencies":[{"issue_id":"mostlyai-engine-g4m.3","depends_on_id":"mostlyai-engine-g4m","type":"parent-child","created_at":"2025-12-10T11:39:15.83719833-08:00","created_by":"daemon"},{"issue_id":"mostlyai-engine-g4m.3","depends_on_id":"mostlyai-engine-g4m.2","type":"blocks","created_at":"2025-12-10T11:39:15.838657777-08:00","created_by":"daemon"}]}
{"id":"mostlyai-engine-g4m.4","title":"Write unit tests for tensor_utils functions","description":"Create tests/test_tensor_utils.py with tests verifying: 1) Output tensor shapes match BatchCollator output, 2) Sequence padding is correct, 3) Windowing produces valid subsequences, 4) Device placement works correctly.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T11:39:21.78613129-08:00","updated_at":"2025-12-10T15:36:00.348651072-08:00","closed_at":"2025-12-10T15:36:00.348651072-08:00","dependencies":[{"issue_id":"mostlyai-engine-g4m.4","depends_on_id":"mostlyai-engine-g4m","type":"parent-child","created_at":"2025-12-10T11:39:21.787284898-08:00","created_by":"daemon"},{"issue_id":"mostlyai-engine-g4m.4","depends_on_id":"mostlyai-engine-g4m.2","type":"blocks","created_at":"2025-12-10T11:39:21.788799114-08:00","created_by":"daemon"}]}
{"id":"mostlyai-engine-g4m.5","title":"Validate tensor interface produces equivalent training results","description":"Run identical training with old BatchCollator path and new tensor interface path. Compare: final loss values (should be within tolerance), training curves shape, model outputs on test data. This validates no regression from the optimization.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T11:39:27.916790386-08:00","updated_at":"2025-12-10T12:37:32.356915346-08:00","closed_at":"2025-12-10T12:37:32.356915346-08:00","dependencies":[{"issue_id":"mostlyai-engine-g4m.5","depends_on_id":"mostlyai-engine-g4m","type":"parent-child","created_at":"2025-12-10T11:39:27.917869244-08:00","created_by":"daemon"},{"issue_id":"mostlyai-engine-g4m.5","depends_on_id":"mostlyai-engine-g4m.3","type":"blocks","created_at":"2025-12-10T11:39:27.919294981-08:00","created_by":"daemon"}]}
{"id":"mostlyai-engine-g4m.6","title":"Run optimized benchmarks and measure improvement","description":"Re-run training_benchmark.py with tensor interface on same 1M row dataset. Compare against baseline: training time reduction, GPU utilization improvement, throughput (samples/sec). Target: 3-5x training speedup, 70%+ GPU utilization.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T11:39:34.184649556-08:00","updated_at":"2025-12-10T15:35:56.357528757-08:00","closed_at":"2025-12-10T15:35:56.357528757-08:00","dependencies":[{"issue_id":"mostlyai-engine-g4m.6","depends_on_id":"mostlyai-engine-g4m","type":"parent-child","created_at":"2025-12-10T11:39:34.186485952-08:00","created_by":"daemon"},{"issue_id":"mostlyai-engine-g4m.6","depends_on_id":"mostlyai-engine-g4m.5","type":"blocks","created_at":"2025-12-10T11:39:34.188880677-08:00","created_by":"daemon"}]}
{"id":"mostlyai-engine-g4m.7","title":"Create Ray Data integration helpers (optional)","description":"Create mostlyai/engine/_tabular/ray_utils.py with create_ray_tensor_loader() helper for seamless Ray Data integration. This is optional - users can use tensor_utils directly with Ray's iter_torch_batches().","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-10T11:39:39.86700746-08:00","updated_at":"2025-12-10T16:18:44.208866731-08:00","closed_at":"2025-12-10T16:18:44.208866731-08:00","dependencies":[{"issue_id":"mostlyai-engine-g4m.7","depends_on_id":"mostlyai-engine-g4m","type":"parent-child","created_at":"2025-12-10T11:39:39.868306747-08:00","created_by":"daemon"},{"issue_id":"mostlyai-engine-g4m.7","depends_on_id":"mostlyai-engine-g4m.3","type":"blocks","created_at":"2025-12-10T11:39:39.870032853-08:00","created_by":"daemon"}]}
{"id":"mostlyai-engine-g4m.8","title":"Extract reusable encoding functions for Ray Data map_batches","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T12:03:21.21389057-08:00","updated_at":"2025-12-10T16:16:08.276643037-08:00","closed_at":"2025-12-10T16:16:08.276643037-08:00","dependencies":[{"issue_id":"mostlyai-engine-g4m.8","depends_on_id":"mostlyai-engine-g4m","type":"parent-child","created_at":"2025-12-10T12:03:21.215035706-08:00","created_by":"daemon"}]}
{"id":"mostlyai-engine-g4m.9","title":"Create model_config builder from analyze() results","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T12:03:21.40504048-08:00","updated_at":"2025-12-10T16:00:37.167970124-08:00","closed_at":"2025-12-10T16:00:37.167970124-08:00","dependencies":[{"issue_id":"mostlyai-engine-g4m.9","depends_on_id":"mostlyai-engine-g4m","type":"parent-child","created_at":"2025-12-10T12:03:21.406316066-08:00","created_by":"daemon"}]}
